<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Personal Website</title>
    <link rel="stylesheet" href="stylesheet.css">
    <meta name="description" content="This is my website, I am Gigi">
    <style>
        body{
             width: 800px;
             background-image: linear-gradient(rgba(255,255,255,0.5), rgba(255,255,255,0.5)), url(https://static.vecteezy.com/system/resources/previews/002/091/724/non_2x/abstract-technology-background-with-big-data-internet-connection-abstract-sense-of-science-and-technology-analytics-concept-graphic-design-illustration-vector.jpg);
             margin: 0 auto;
        font-size: medium;
        font-family: Arial, Helvetica, sans-serif;    
    }
        img{ 
            width: 800px;
            }
        /* select certain id */

    </style>
</head>

<body>
    <h1 style="color:rgb(187, 45, 45)">Big Data</h1>
    <hr />
    <div>
        <h2>Table of Content</h2>
        <Ul><Li><a href="#sec1">Introduction</a></Li>
        <Li><a href="#sec2">Defination</a></Li>
        <Li><a href="#sec3">Technologies</a></Li></Ul>
    </div>
    <img src="big data.jpg" alt="intro to big data">
    <p>Big data refers to data sets that are too large or complex to be dealt with by traditional data-processing application software. Data with many fields (rows) offer greater statistical power, while data with higher complexity (more attributes or columns) may lead to a higher false discovery rate.[2] Big data analysis challenges include capturing data, data storage, data analysis, search, sharing, transfer, visualization, querying, updating, information privacy, and data source. Big data was originally associated with three key concepts: volume, variety, and velocity.[3] The analysis of big data presents challenges in sampling, and thus previously allowing for only observations and sampling. Thus a fourth concept, veracity, refers to the quality or insightfulness of the data. Without sufficient investment in expertise for big data veracity, then the volume and variety of data can produce costs and risks that exceed an organization's capacity to create and capture value from big data.[4]</p>
    <h2 id = "sec1">Introduction</h2>
    <p><a href="https://en.wikipedia.org/wiki/Big_data">Current usage of the term big data</a> tends to refer to the use of predictive analytics, user behavior analytics, or certain other advanced data analytics methods that extract value from big data, and seldom to a particular size of data set. "There is little doubt that the quantities of data now available are indeed large, but that's not the most relevant characteristic of this new data ecosystem."[5] Analysis of data sets can find new correlations to "spot business trends, prevent diseases, combat crime and so on".[6] Scientists, business executives, medical practitioners, advertising and governments alike regularly meet difficulties with large data-sets in areas including Internet searches, fintech, healthcare analytics, geographic information systems, urban informatics, and business informatics. Scientists encounter limitations in e-Science work, including meteorology, genomics,[7] connectomics, complex physics simulations, biology, and environmental research.</p>
    <br>The size and number of available data sets have grown rapidly as data is collected by devices such as mobile devices, cheap and numerous information-sensing Internet of things devices, aerial (remote sensing), software logs, cameras, microphones, radio-frequency identification (RFID) readers and wireless sensor networks.[9][10] The world's technological per-capita capacity to store information has roughly doubled every 40 months since the 1980s;[11] as of 2012, every day 2.5 exabytes (2.5×260 bytes) of data are generated.[12] Based on an IDC report prediction, the global data volume was predicted to grow exponentially from 4.4 zettabytes to 44 zettabytes between 2013 and 2020. By 2025, IDC predicts there will be 163 zettabytes of data.[13] According to IDC, global spending on big data and business analytics (BDA) solutions is estimated to reach $215.7 billion in 2021.[14][15] While Statista report, the global big data market is forecasted to grow to $103 billion by 2027.[16] In 2011 McKinsey & Company reported, if US healthcare were to use big data creatively and effectively to drive efficiency and quality, the sector could create more than $300 billion in value every year.[17] In the developed economies of Europe, government administrators could save more than €100 billion ($149 billion) in operational efficiency improvements alone by using big data.[17] And users of services enabled by personal-location data could capture $600 billion in consumer surplus.[17] One question for large enterprises is determining who should own big-data initiatives that affect the entire organization.
    <h2 id ="sec2">Defination</h2>
    <p>The term big data has been in use since the 1990s, with some giving credit to John Mashey for popularizing the term.[21][22] Big data usually includes data sets with sizes beyond the ability of commonly used software tools to capture, curate, manage, and process data within a tolerable elapsed time.[23] Big data philosophy encompasses unstructured, semi-structured and structured data; however, the main focus is on unstructured data.[24] Big data "size" is a constantly moving target; as of 2012 ranging from a few dozen terabytes to many zettabytes of data.[25] Big data requires a set of techniques and technologies with new forms of integration to reveal insights from data-sets that are diverse, complex, and of a massive scale.</p>
    <h2 id = "sec3">Technologies</h2>
    <p>A 2011 McKinsey Global Institute report characterizes the main components and ecosystem of big data as follows:[51]

        Techniques for analyzing data, such as A/B testing, machine learning, and natural language processing
        Big data technologies, like business intelligence, cloud computing, and databases
        Visualization, such as charts, graphs, and other displays of the data
        Multidimensional big data can also be represented as OLAP data cubes or, mathematically, tensors. Array database systems have set out to provide storage and high-level query support on this data type. Additional technologies being applied to big data include efficient tensor-based computation,[52] such as multilinear subspace learning,[53] massively parallel-processing (MPP) databases, search-based applications, data mining,[54] distributed file systems, distributed cache (e.g., burst buffer and Memcached), distributed databases, cloud and HPC-based infrastructure (applications, storage and computing resources),[55] and the Internet.[citation needed] Although, many approaches and technologies have been developed, it still remains difficult to carry out machine learning with big data.</p>
        <br>Some MPP relational databases have the ability to store and manage petabytes of data. Implicit is the ability to load, monitor, back up, and optimize the use of the large data tables in the RDBMS.
        <br>DARPA's Topological Data Analysis program seeks the fundamental structure of massive data sets and in 2008 the technology went public with the launch of a company called "Ayasdi". <br>
        <strong>big data</strong>
</body>
</html>